{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nel-eleven11/Lab9_IA/blob/main/lab9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qJUuiplei9t"
      },
      "source": [
        "#Laboratorio 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqlNgDWqelG_"
      },
      "source": [
        "## Task 1 - Teoría\n",
        "\n",
        "Responda las siguientes preguntas de forma clara y concisa, pueden subir un PDF bien dentro del mismo Jupyter Notebook.\n",
        "\n",
        "1. Diga cual es la diferencia entre Modelos de Markov y Hidden Markov Models\n",
        "\n",
        "En el caso de los modelos de markov, estos son modelos estocásticos donde se tiene la condición de que el sistema actual depende únicamente del estado anterior, lo cuál es la propiedad de markov. En estos modelos los estados son completamente observables, no hay información oculta y las transiciones entre los estados tienen probabilidad fijas generalmente relacionadas a una matriz de probabilidades. En el caso de los Hidden Markov models, estos son una extensión de los modelos de markov donde hay mayor ambiguedad debido a que el ambiente no es completamente observable, hay estados ocultos. Ahora bien, los estados ocultos no son indetectables ya que de igual manera estos \"emiten señales\" indirectamente llamadas emisiones observables. Aunque sea más complejo es útil para poder modelar situaciones más reales donde no se puede predecir completamente sobre el ambiente y es necesario hacer inferencias debido a estados ocultos. En los HMM se ven las emisiones probocadas por los estados ocultos. Importante mencionar, que aquí se está hablando de solo 1 cadena.\n",
        "\n",
        "2. Investigue qué son los factorial HMM (Hidden Markov Models)\n",
        "\n",
        "Estos son una extensión de los HMM que tiene como proposito ayudar a modelar sistemas más complejos. Sistmas donde distintios procesos independientes pueden influir en las observaciones/emisiones. En este caso no solo tenemos una cadena oculta, sin varios cadenas que influyen en las observaciones. A diferencia del modelo original de HMM que toma en consideración solo 1 cadena para una observación. Este modelos es útil en situaciones complejas cuando un evento puede estar afectado por varas cadenas de markov ocultas. Por ejemplo en el diagnóstico médico. Si se ven los síntomas de un paciente, las enfermedades causantes de la condición del paciente pueden ser varias. Estas enfermedades son independientes unas de otras y puede que los síntomas puedan ser por culpa de alguna de ellas o de ambas. \n",
        "\n",
        "3. Especifique en sus propias palabras el algoritmo Forward Backward para HMM\n",
        "\n",
        "Por lo que entiendo el Algoritmo Forward backward para HMM sirve principalmente para determinar las probabilidades de estar en cada uno de los estados ocultos tomando en cuenta tanto el presente como el futuro, dada una secuencia completa de observaciones en un tiempo. El algoritmo tiene 2 fases principales: el \"Forward\" y el \"Backward\". Al avanzar en las observaciones en el tiempo, se calculan las probabilidades de estar en un estado específico tomando solo en cuenta las observaciones que se tienen hasta ese momento. Esta probabilidad parcial se cálcula para los posibles estados ocultos a medida que avanzamos en las observaciones. Luego es cuando viene la segunda fase \"Backward\", que como indica el normal lo que se hace es revisar las observaciones hacia atras (generalmente de forma recursiva). De tal forma que ahora se cálcula como las observaciones futuras afectan a la probabilidad de estar en un estado. El backward no modifica directamente la probabilidad sino que ayuda a obtener un factor de ajuste para las probabilidades previamente calculadas con el backward. Luego de hacer estos 2 algoritmos se hace algo llamado \"Probabilidad suavizada\" que es la combinación de ambos cálculos para obtener las probabilidades de estados ocultos dadas las observaciones.\n",
        "\n",
        "4. En el algoritmo de Forward Backward, por qué es necesario el paso de backward (puede escribir ejemplos o casos para responder esta pregunta)\n",
        "\n",
        "Si solo se utilizara el forward no quiere decir que fuera incorrecto, pero si sería un tanto incompleto. Con el forward se van calculando las probabilidades con las observaciones sin tomar en cuenta el futuro. Por lo que las estimasiones no son completas, porque en cada paso no se sabe lo que realmente pasó al final y solo se toman en cuenta las observaciones hasta ese momento (observaciones pasadas). Por ejemplo, si estamos hablando del clima, siendo los estados ocultos el clima real y las observaciones el comportamiento de la gente se puede ver de la siguiente forma:\n",
        "\n",
        "Observaciones: \n",
        "* día 1:\"las personas llevan sombrilla\"\n",
        "* día 2:\"las personas llevan lentes de sol\"\n",
        "\n",
        "Si calculamos la probabilidad de haber estado en un día con lluvia (estado oculto) en el día 1, la probabilidad sería alta si solo tomamos en cuenta la observación hasta el día 1. Pero en el siguiente día la observación indica que hay personas usando lentes de sol, probablemente ese día fue soleado. Con la ayuda de la parte de backward lo que se busca al final es tomar en cuenta el futuro para poder alterar las probabilidades ya calculadas. En el contexto de la situación planteada si luego de un día probablemente \"lluvioso\" el día es \"soleado\" (o probablemente soleado), debería hacerse un ajuste de la probabilidad del día lluvioso ya que en el futuro hay observaciones que podrían implicar que la probabilidad de haber alcanzado el estado oculto \"lluvia\" sería menor. Este ajuste se hace por medio de las probabilidades definidas en una matriz de transcición claramente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhMkBy0Menva"
      },
      "source": [
        "## Task 2 - Algoritmo Forward Backward en HMM\n",
        "\n",
        "El algoritmo forward-backward se basa en una forma de programación dinámica.Para este task deberán investigar sobre el mismo. En este ejercicio estamos ante un modelo meteorológico representado por un Modelo Oculto de Markov (HMM) con dos estados: \"Soleado\" y \"Lluvioso\". Queremos predecir el tiempo en un día determinado basándonos en las observaciones de si el día anterior estuvo soleado o lluvioso. Para ello considere el siguiente código como una guía:\n",
        "\n",
        "Con esto, considere lo siguiente:\n",
        "1. Defina los parámetros del modelo oculto de Markov (HMM), incluidos estados, observaciones,\n",
        "probabilidades iniciales, probabilidades de transición y probabilidades de emisión.\n",
        "2. Cree una instancia de la clase HMM con los parámetros definidos.\n",
        "3. Genere una secuencia de observaciones utilizando el método generate_sequence. Este paso es opcional\n",
        "pero útil para realizar pruebas.\n",
        "4. Utilice el método forward para calcular las probabilidades directas, que representan la probabilidad de\n",
        "observar una secuencia particular de observaciones hasta un paso de tiempo específico y estar en un estado\n",
        "particular en ese paso de tiempo.\n",
        "5. Utilice el método backward para calcular las probabilidades hacia atrás, que representan la probabilidad de\n",
        "observar la secuencia restante desde un paso de tiempo específico hasta el final de la secuencia, dado que\n",
        "el sistema se encuentra en un estado particular en ese paso de tiempo.\n",
        "6. Utilice el método compute_state_probabilities para calcular las probabilidades de estar en cada\n",
        "estado en cada paso de tiempo dada la secuencia observada. Este paso implica combinar las probabilidades\n",
        "hacia adelante y hacia atrás.\n",
        "7. Imprima o analice las probabilidades calculadas según sea necesario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-HSDbmCeec4A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Secuencia Generada: None\n",
            "\n",
            "Probabilidades Forward:\n",
            "None\n",
            "\n",
            "Probabilidades Backward:\n",
            "None\n",
            "\n",
            "Probabilidades de Estado:\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "class HMM:\n",
        "    def __init__(self, states, observations, initial_prob, transition_prob, emission_prob):\n",
        "        \"\"\"Inicializar parámetros de HMM\"\"\"\n",
        "        self.states = states\n",
        "        self.observations = observations\n",
        "        self.initial_prob = initial_prob\n",
        "        self.transition_prob = transition_prob\n",
        "        self.emission_prob = emission_prob\n",
        "\n",
        "    def generate_sequence(self, length):\n",
        "        \"\"\"Generar una secuencia de observaciones basada en el HMM.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def forward(self, observations):\n",
        "        \"\"\"Implementar el paso hacia adelante del algoritmo hacia adelante.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def backward(self, observations):\n",
        "        \"\"\"Implementar el paso hacia atrás del algoritmo hacia adelante.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def compute_state_probabilities(self, observations):\n",
        "        \"\"\"Combine probabilidades hacia adelante y hacia atrás para calcular probabilidades de estado\"\"\"\n",
        "        pass\n",
        "\n",
        "# Uso y datos\n",
        "states = ['Sunny', 'Rainy']\n",
        "observations = ['Sunny', 'Sunny', 'Rainy']\n",
        "initial_prob = {'Sunny': 0.5, 'Rainy': 0.5}\n",
        "transition_prob = {'Sunny': {'Sunny': 0.8, 'Rainy': 0.2}, 'Rainy': {'Sunny': 0.4, 'Rainy': 0.6}}\n",
        "emission_prob = {'Sunny': {'Sunny': 0.8, 'Rainy': 0.2}, 'Rainy': {'Sunny': 0.3, 'Rainy': 0.7}}\n",
        "\n",
        "hmm = HMM(states, observations, initial_prob, transition_prob, emission_prob)\n",
        "\n",
        "# Generar una secuencia de observaciones.\n",
        "obs_sequence = hmm.generate_sequence(5)\n",
        "print(\"Secuencia Generada:\", obs_sequence)\n",
        "\n",
        "# Calculo de probabilidades forward\n",
        "forward_probs = hmm.forward(observations)\n",
        "print(\"\\nProbabilidades Forward:\")\n",
        "print(forward_probs)\n",
        "\n",
        "# Calculo de probabilidades backward\n",
        "backward_probs = hmm.backward(observations)\n",
        "print(\"\\nProbabilidades Backward:\")\n",
        "print(backward_probs)\n",
        "\n",
        "# Calcular probabilidades de estado\n",
        "state_probs = hmm.compute_state_probabilities(observations)\n",
        "print(\"\\nProbabilidades de Estado:\")\n",
        "print(state_probs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNXrvrIPOqOWSvNrPfohgY6",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
